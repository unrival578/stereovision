{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Author: Justin Clancy, University of Melbourne, 2020                                 #\n",
    "# Creating depth maps for stereo images                                                #\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import fftconvolve\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import images from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to import all images in a folder\n",
    "\n",
    "def import_images(folder):\n",
    "    # create an empty list to fill with image data\n",
    "    images = []\n",
    "    # Search through the folder for files\n",
    "    for filename in os.listdir(folder):\n",
    "        # An image is loaded\n",
    "        image = cv.imread(os.path.join(folder,filename))\n",
    "        # Add the image to the list if it actually has\n",
    "        # data in it\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "    # Since all our folders just have 2 images\n",
    "    # save the first as the pattern (left) and second\n",
    "    # as the template (right)\n",
    "    pattern_col = images[0]\n",
    "    template_col = images[1]\n",
    "    # Convert to greyscale with rgb weights\n",
    "    cols = [0.2989,0.5870,0.1140]\n",
    "    pattern = np.dot(pattern_col[...,:3],cols)\n",
    "    template = np.dot(template_col[...,:3],cols)\n",
    "    return pattern, template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window function to take the left image and \n",
    "# cut it into n sub windows that preserve the 'physical'\n",
    "# layout of the input\n",
    "\n",
    "def windows(left_im, y_win, x_win):\n",
    "    # Obtain the dimensions of the left image\n",
    "    height, width = left_im.shape\n",
    "    # Condition that the input num x and y windows must be\n",
    "    # divisible by the height and width of the original image\n",
    "    assert height % y_win == 0,\"{} width isn't evenly divisble by {}!\".format(height, y_win)\n",
    "    assert width % x_win == 0,\"{} height isn't evenly divisble by {}\".format(width, x_win)\n",
    "    # Reshape the input image by the desired x and y input\n",
    "    return (left_im.reshape(height//y_win, y_win, -1, x_win)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, x_win, y_win))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to follow the above idea, howver allowing\n",
    "# for the windows to overlap by a predefined\n",
    "# amount.\n",
    "\n",
    "def overlap_windows(left_im, y_win, x_win, overlap):\n",
    "    \n",
    "    # Define array size length in bytes and dimensions in x and y\n",
    "    size = left_im.itemsize\n",
    "    shape = left_im.shape\n",
    "\n",
    "    # Strides map indicies of one array to positions in the data\n",
    "    # buffer, this process here is mapping out the windows to slide\n",
    "    # across the left image\n",
    "    strides = (size*shape[1]*(y_win-overlap), \n",
    "               size*(x_win-overlap),\n",
    "               size*shape[1], size)\n",
    "    # Window dimensions\n",
    "    shape = (int((shape[0] - x_win)/(x_win-overlap))+1,\n",
    "             int((shape[1] - y_win)/(y_win-overlap))+1 ,\n",
    "             y_win, x_win)\n",
    "    windowsy=shape[0]\n",
    "    windowsx=shape[1]\n",
    "\n",
    "    # Return a view of the input array with the defined shape and strides\n",
    "    # i.e., return a cut up version of the left image\n",
    "    return np.lib.stride_tricks.as_strided(left_im, strides=strides,\n",
    "                                              shape=shape ).reshape(-1, y_win,\n",
    "                                                                    x_win),windowsy,windowsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the search area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to define the search area\n",
    "# For each window in the left we need to look for its location in the right\n",
    "\n",
    "def find_window(right_im,center,win_dim,im_dim,num_win):\n",
    "\n",
    "    # Get center coordinates from the center of a window\n",
    "    center_x,center_y = center\n",
    "    \n",
    "    # Maximum value of x and y from template original images\n",
    "    maxy,maxx = im_dim \n",
    "    \n",
    "    # Get left image window dimensions\n",
    "    winx,winy = win_dim\n",
    "    # Define the search area as multiples of the windows in a square\n",
    "    search_x = winx*num_win\n",
    "    search_y = winy*num_win\n",
    "    \n",
    "    # Define the area in the right image to search\n",
    "    # minimum x coordinate, making sure its cut off at zero\n",
    "    left = center_x - search_x\n",
    "    if left <= 0:\n",
    "        left = 0\n",
    "        right = left + search_x\n",
    "    else:\n",
    "        left = left\n",
    "        right = left + search_x\n",
    "        if right >= maxy:\n",
    "            right = maxy\n",
    "            left = maxy - search_x\n",
    "        else: \n",
    "            left = left\n",
    "            right = right\n",
    "\n",
    "    # minimum y coordinate ensuring it cuts off at zero\n",
    "    bottom = center_y - search_y\n",
    "    if bottom <= 0:\n",
    "        bottom = 0\n",
    "        top = bottom + search_y\n",
    "    else:\n",
    "        bottom = bottom\n",
    "        top = bottom + search_y\n",
    "        if top >= maxx:\n",
    "            top = maxx\n",
    "            bottom = maxx - search_y\n",
    "        else:\n",
    "            top = top\n",
    "            bottom = bottom\n",
    "        \n",
    "    # Return the search window in the right image\n",
    "    \n",
    "    right_win = right_im[left:right,bottom:top]\n",
    "\n",
    "    return right_win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now offset for a window.\n",
    "# This function should take the pattern window and a search area, \n",
    "# returning the best lag (x,y) for the window in the search area.\n",
    "\n",
    "def b_lag(scores,pattern):\n",
    "    # Check for the best lag as a position in x and y separetly\n",
    "    y,x  = np.unravel_index(np.argmax(scores,axis=None),scores.shape)\n",
    "    # Make sure the best lag points correspond to roughly the centre of the\n",
    "    # pattern so if we put a marker on this location its right in the middle\n",
    "    xmid = x + pattern.shape[1]/2\n",
    "    ymid = y + pattern.shape[0]/2\n",
    "    high_score = np.max(scores)\n",
    "    return xmid,ymid,high_score\n",
    "\n",
    "def window_offset(pattern_window,search_area):\n",
    "    # Mean shift the windowed pattern and template\n",
    "    #mean_s = search_area - np.mean(search_area)\n",
    "    #mean_p = pattern_window - np.mean(pattern_window)\n",
    "    mean_s = pattern_window\n",
    "    mean_p = pattern_window\n",
    "    empty_template = np.ones(mean_s.shape)\n",
    "    score_array = fftconvolve(mean_p,mean_s.conj(),mode='full')\n",
    "    \n",
    "    mean_p = fftconvolve(np.square(mean_p),empty_template,mode='full') - \\\n",
    "                np.square(fftconvolve(mean_p,empty_template,mode='full')) \\\n",
    "                    / (np.prod(mean_s.shape))\n",
    "    \n",
    "    mean_p[np.where(mean_p < 0)] = 0\n",
    "    mean_s = np.sum(np.square(mean_s))\n",
    "    score_array = score_array / np.sqrt(mean_p * mean_s)\n",
    "    \n",
    "    score_array[np.where(np.logical_not(np.isfinite(score_array)))]\n",
    "    bl_y,bl_x,s_max = b_lag(score_array,pattern_window)\n",
    "    \n",
    "    return bl_x,bl_y,s_max,score_array\n",
    "    \n",
    "from skimage.feature import match_template\n",
    "def test(pattern,template):\n",
    "    score_arr = match_template(pattern,template)\n",
    "    bl_y,bl_x,s_max = b_lag(score_arr,pattern)\n",
    "    return s_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_map(folder, window_size = (20,20), overlap_perc = 50, search_ext = 3):\n",
    "    # Import the left and right image from folder\n",
    "    pattern,template = import_images(folder)\n",
    "    \n",
    "    # Define image dimensions\n",
    "    templatey,templatex = template.shape\n",
    "    patterny,patternx = pattern.shape\n",
    "    \n",
    "    # The images have slightly different shapes so make them equal \n",
    "    # with slight padding\n",
    "    new_dimx = patternx + 2\n",
    "    new_dimy = patterny + 2\n",
    "    right_im = np.zeros((new_dimy,new_dimx))\n",
    "    right_im[:templatey,:templatex] = template\n",
    "    left_im = np.zeros((new_dimy,new_dimx))\n",
    "    left_im[:patterny,:patternx] = pattern\n",
    "    \n",
    "    # Define overlap from input percentage\n",
    "    win_x = window_size[1]\n",
    "    win_x0 = np.int(win_x/2)   # Center of window (x)\n",
    "    win_y = window_size[0]\n",
    "    win_y0 = np.int(win_y/2)   # Center of window (y)\n",
    "    olap = np.int(win_x/(100/overlap_perc))\n",
    "    \n",
    "    # Cut up the left image into equal sized windowed of defined\n",
    "    # shape and overlap \n",
    "    left_windows = overlap_windows(left_im,win_y,win_x,olap)\n",
    "\n",
    "    window_dim = (left_windows[1],left_windows[2])\n",
    "    \n",
    "    #olap = win_x - olap\n",
    "    depth_map = np.zeros(window_dim)\n",
    "    winy = left_windows[1]\n",
    "    winx = left_windows[2]\n",
    "\n",
    "    \n",
    "    for i in np.arange(winy):\n",
    "        for j in np.arange(winx):\n",
    "            search = find_window(template,(win_y0 + i*olap,win_x0 + j*olap),(win_y,win_x),pattern.shape,search_ext)\n",
    "            score = test(search,left_windows[0][i*winx+j])\n",
    "            depth_map[i,j] = depth_map[i,j] + score\n",
    "\n",
    "    plt.imshow(depth_map)\n",
    "\n",
    "    plt.title('Depth Map')\n",
    "    cbar = plt.colorbar(orientation='horizontal')\n",
    "    cbar.set_label('Cross-Correlation Score')\n",
    "    plt.show()\n",
    "    \n",
    "    # Some of the clearest results can be found with the following settings\n",
    "    \n",
    "    # Block:\n",
    "    # Window size = (25,25)\n",
    "    # Search extent = 10\n",
    "    \n",
    "    # Rubiks Cube:\n",
    "    # Window size = (15,15)\n",
    "    # Search extent = 5\n",
    "    \n",
    "    # Giraffes: \n",
    "    # Window size = (25,25)\n",
    "    # Search extent = 20\n",
    "    \n",
    "    # Pinecone:\n",
    "    # Window size = (50,50)\n",
    "    # Search extent - 4\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input folder destination, window size dimensions, overlap percentage and search extent multiplier\n",
    "\n",
    "depth_map('',window_size = (,), overlap_perc=,search_ext=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
