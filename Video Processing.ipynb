{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Author: Justin Clancy, University of Melbourne, 2020                                 #\n",
    "# - Extension Project -                                                                #\n",
    "# Creating Depth Maps from Stereo Video                                                #\n",
    "# + Camera Calibration Functions (not explicitly used but written)                     #\n",
    "# Note: functions were ran with less than optimal equipment available, if aquired,     #\n",
    "# this would be best ran with a proper stereo camera set up such as the stereoPI       #\n",
    "# stereo camera designed for RaspberryPI programmable boards                           #\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Videos and cut into frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_ims(pathIn, pathOut):\n",
    "    \n",
    "    # Video file\n",
    "    vidcap = cv.VideoCapture(pathIn)\n",
    "    success,image = vidcap.read()\n",
    "    \n",
    "    # Framerate\n",
    "    fps = int(vidcap.get(cv.CAP_PROP_FPS))\n",
    "    length = int(vidcap.get(cv.CAP_PROP_FRAME_COUNT)) # Number of frames\n",
    "\n",
    "    # Print footage properties\n",
    "    print('FPS:',fps) # Frames per second\n",
    "    print('Extracting every {} frames'.format(1))\n",
    "    print('Total Frames:',length)\n",
    "    print('Number of Frames Saved:', (length // 1) + 1)\n",
    "    \n",
    "    # Iterate over all frames and separate them into individual images\n",
    "    count = 0\n",
    "    success = True\n",
    "    # Limit to length of video\n",
    "    while count <= length:\n",
    "        vidcap.set(cv.CAP_PROP_POS_FRAMES,count/2)\n",
    "        success,image = vidcap.read()\n",
    "        # Convert to grayscale\n",
    "        gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "        # Save frame as a .jpg with frame number\n",
    "        cv.imwrite(pathOut+\"//left_frame%000d.jpg\"%count, gray) \n",
    "        count += 1\n",
    "        \n",
    "def right_ims(pathIn, pathOut):\n",
    "    # Follows same process as above for the right video\n",
    "    vidcap = cv.VideoCapture(pathIn)\n",
    "    success,image = vidcap.read()\n",
    "    \n",
    "    fps = int(vidcap.get(cv.CAP_PROP_FPS))\n",
    "    length = int(vidcap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Print footage properties\n",
    "    print('FPS:',fps) # Frames per second\n",
    "    print('Extracting every {} frames'.format(1))\n",
    "    print('Total Frames:',length)\n",
    "    print('Number of Frames Saved:', (length // 1) + 1)\n",
    "    \n",
    "    count = 0\n",
    "    success = True\n",
    "    while count <= length:\n",
    "        vidcap.set(cv.CAP_PROP_POS_FRAMES,count/2)\n",
    "        success,image = vidcap.read() \n",
    "        gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "        cv.imwrite( pathOut + \"\\\\right_frame%000d.jpg\" % count, gray)\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to generate a depth map from stereo frames\n",
    "# with inputs of file names, number of disparities, block size\n",
    "# and minimum disparity (minimum depth to check)\n",
    "\n",
    "\n",
    "def frame_depth(frame_L,frame_R,numDisp=50,blockSz=2,min_disp=10):\n",
    "    window_size = 2\n",
    "    # Stereo calibration settings discussed in report, follows pretty\n",
    "    # closely to the settings needed for the custom depth maps previously\n",
    "    # generated\n",
    "    stereo = cv.StereoSGBM_create(minDisparity = min_disp,\n",
    "                                  numDisparities = numDisp,\n",
    "                                  blockSize = blockSz,\n",
    "                                  P1 = 8*3*window_size**2,\n",
    "                                  P2 = 32*3*window_size**2,\n",
    "                                  disp12MaxDiff = 10,\n",
    "                                  uniquenessRatio = 10,\n",
    "                                  speckleWindowSize = 1,\n",
    "                                  speckleRange = 2)\n",
    "    # Generate the map\n",
    "    disparity = stereo.compute(frame_L,frame_R)\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Frames in an Iteratable array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all frames from a folder and save in a list to be\n",
    "# iterated over\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Video Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_video(input_folder):\n",
    "    # Define left and right video\n",
    "    left_vid = input_folder+'left.mp4'\n",
    "    right_vid = input_folder+'right.mp4'\n",
    "    \n",
    "    # Create folders for the left and right frames\n",
    "    dir = os.path.join(input_folder,'left')\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    dir = os.path.join(input_folder,'right')\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        \n",
    "    # Cut left and right videos into frames, save in new folders\n",
    "    left_ims(left_vid,input_folder+'/left')\n",
    "    right_ims(right_vid,input_folder+'/right')\n",
    "\n",
    "    # Load all images from each folder into arrays\n",
    "    left_frames = load_images(input_folder+'left')\n",
    "    right_frames = load_images(input_folder+'right')\n",
    "    \n",
    "    # Create disparity array from left and right images\n",
    "    depth_frames = []\n",
    "    framesl = len(left_frames)\n",
    "    framesr = len(right_frames)\n",
    "    \n",
    "    # Ensure that the generated disparity video length is\n",
    "    # only as long as the shortest of the two stereo videos.\n",
    "    # Ideally they would be the same but this accounts for \n",
    "    # error.\n",
    "    if framesl > framesr:\n",
    "        length = framesr\n",
    "    else:\n",
    "        length = framesl\n",
    "        \n",
    "    # Iterate over images and generate depth maps, saving them to a \n",
    "    # larger array\n",
    "    for i in np.arange(length):        \n",
    "        # Adjust which of these is commented if wanting to see the difference in quality conversion\n",
    "        #depth_frames.append(frame_depth(left_frames[i],right_frames[i]).astype(np.uint8)) # Supresses warnings but loses quality\n",
    "        depth_frames.append(frame_depth(left_frames[i],right_frames[i])) # Has lossy conversion but still better quality\n",
    "\n",
    "    # Create gif\n",
    "    imageio.mimsave(input_folder+'depth.gif',depth_frames)\n",
    "    return depth_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate depth video\n",
    "# NOTE: lossy conversion will occur but it is still better than\n",
    "# converting to uint8 as suggested. The option is available by\n",
    "# changing which depth_frames.append line is commented out\n",
    "# in the iteration above.\n",
    "\n",
    "disp = depth_video('/Users/justi/Desktop/comp_test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Calibration Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was not applied in practice due to lack of time and equipment\n",
    "# suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import one extra module\n",
    "import glob\n",
    "\n",
    "# This task utilizes a 'chess board' pattern as a grid of squares\n",
    "# with known distances between corners. Analagous to the dot pattern\n",
    "# explained in the report\n",
    "def calibration(folder):\n",
    "\n",
    "    # Define termination criteria\n",
    "    stop = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 50, 0.0001)\n",
    "\n",
    "    # Define corner points by board size\n",
    "    obj_points = np.zeros((8*8,3),np.float32) # Stanard 8x8 board\n",
    "    obj_points[:,:2] = np.mgrid[0:8,0:8].T.reshape(-1,2)\n",
    "\n",
    "    # Define empty lists to store object and image points\n",
    "    obj_p = [] # Real Space (x,y,z)\n",
    "    img_p = [] # Image plane (pixels: i,j)\n",
    "\n",
    "    # Retrieve files of jpg format\n",
    "    images = glob.glob(folder+'*.jpg')\n",
    "\n",
    "    for file in images:\n",
    "        # Read image\n",
    "        img = cv.imread(file)\n",
    "        # Convert to grayscale\n",
    "        gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Locate corners\n",
    "        success,corner = cv.findChessboardCorners(gray,(8,8),None)\n",
    "\n",
    "        # If they are found, add to object points and image points\n",
    "        if success == True:\n",
    "            obj_p.append(obj_points)\n",
    "\n",
    "            # Refine corners\n",
    "            ref_corner = cv.cornerSubPix(gray,corner,(11,11),(-1,-1),stop)\n",
    "            img_p.append(ref_corner)\n",
    "\n",
    "            # Draw corners\n",
    "            img = cv.drawChessboardCorners(img,(8,8),ref_corner,success)\n",
    "            cv.imshow('img',img)\n",
    "            cv.waitKey(500)\n",
    "\n",
    "    # Now return a camera matrix, distortion coefficients, rotation and \n",
    "    # translation vectors\n",
    "    success,cam_m,dist_coeff,rot_vec,tran_vec = cv.calibrateCamera(obj_points,\n",
    "                                                                   img_points,\n",
    "                                                                  gray.shape[::-1],\n",
    "                                                                  None,\n",
    "                                                                  None)\n",
    "    return cam_m,dist_coeff,rot_vec,tran_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistort Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the above code with calibration images to obtain calibration\n",
    "# matrix to then apply to all frames\n",
    "\"\"\"\n",
    "camera_matrix = calibration(folder)[0]\n",
    "dist_coeff = calibration(folder[1])\n",
    "\"\"\"\n",
    "\n",
    "# Read frames\n",
    "def undistort(frame_name,camera_matrix,dist_coeff):\n",
    "    frame = cv.imread(frame_name)\n",
    "    height,width = frame.shape[:2]\n",
    "    new_cam_m, image_region = cv.getOptimalNewCameraMatrix(camera_matrix,\n",
    "                                                          dist_coeff,\n",
    "                                                          (width,height),\n",
    "                                                          1,\n",
    "                                                          (width,height))\n",
    "\n",
    "    # Remap frames\n",
    "    x_map,y_map = cv.initUndistortRectifyMap(camera_matrix,\n",
    "                                            dist_coeff,\n",
    "                                            new_cam_m\n",
    "                                            (width,height),\n",
    "                                            5)\n",
    "    distortion = cv.remap(frame,x_map,y_map,cv.INTER_LINEAR)\n",
    "\n",
    "    # Crop the frame\n",
    "    x,y,w,h = image_region\n",
    "    # This cropped frame will be straighted and fully undistorted\n",
    "    distortion = distortion[y:y+h,x:x+w]\n",
    "    cv.imwrite(frame_name+'_calibrated.jpg',distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
